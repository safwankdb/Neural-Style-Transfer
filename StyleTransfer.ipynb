{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleTransfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfnOAy3juWkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision as tv\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPgpK8LzCTZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_tensor = tv.transforms.Compose([\n",
        "                tv.transforms.Resize((512,512)),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[1, 1, 1]),\n",
        "            ])\n",
        "\n",
        "unload = tv.transforms.Compose([\n",
        "                tv.transforms.Normalize(mean=[-0.485,-0.456,-0.406],\n",
        "                                    std=[1,1,1]),                \n",
        "                tv.transforms.Lambda(lambda x: x.clamp(0,1))\n",
        "            ])\n",
        "to_image = tv.transforms.ToPILImage()\n",
        "\n",
        "style_img = 'udnie.jpg'\n",
        "input_img = 'chicago.jpg'\n",
        "\n",
        "style_img = Image.open(style_img)\n",
        "input_img = Image.open(input_img)\n",
        "\n",
        "style_img = to_tensor(style_img).cuda()\n",
        "input_img = to_tensor(input_img).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjHbdcimXU0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(module, x, y):\n",
        "#     print('here')\n",
        "    features.append(y)\n",
        "    \n",
        "def gram_matrix(x):\n",
        "    \n",
        "    b, c, h, w = x.size()\n",
        "    F = x.view(b,c,h*w)\n",
        "    G = torch.bmm(F, F.transpose(1,2))/(h*w)\n",
        "    return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz8SE9zRJWnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VGG = tv.models.vgg19(pretrained=True).features\n",
        "VGG.cuda()\n",
        "\n",
        "for i, layer in enumerate(VGG):\n",
        "    \n",
        "    if i in [0,5,10,19,21,28]:\n",
        "        VGG[i].register_forward_hook(get_features)\n",
        "    \n",
        "    elif isinstance(layer, nn.MaxPool2d):\n",
        "        VGG[i] = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "VGG.eval()\n",
        "\n",
        "for p in VGG.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "features = []\n",
        "VGG(input_img.unsqueeze(0))\n",
        "c_target = features[4].detach()\n",
        "\n",
        "features = []\n",
        "VGG(style_img.unsqueeze(0))\n",
        "f_targets = features[:4]+features[5:]\n",
        "gram_targets = [gram_matrix(i).detach() for i in f_targets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPlMTW3OJWqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 1\n",
        "beta = 1e3\n",
        "iterations = 200\n",
        "image = input_img.clone().unsqueeze(0)\n",
        "# image = torch.randn(1,3,512,512).cuda()\n",
        "images = []\n",
        "optimizer = optim.LBFGS([\n",
        "image.requires_grad_()], lr=1)    \n",
        "mse_loss = nn.MSELoss(reduction='mean')\n",
        "l_c = []\n",
        "l_s = []\n",
        "counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROOadvlTejzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for itr in range(iterations):\n",
        "\n",
        "    features = []\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        VGG(image)\n",
        "        t_features = features[-6:]\n",
        "        content = t_features[4]\n",
        "        style_features = t_features[:4]+t_features[5:]\n",
        "        t_features = []\n",
        "        gram_styles = [gram_matrix(i) for i in style_features]\n",
        "        c_loss = alpha * mse_loss(content, c_target)\n",
        "        s_loss = 0\n",
        "\n",
        "        for i in range(5):\n",
        "            n_c = gram_styles[i].shape[0]\n",
        "            s_loss += beta * mse_loss(gram_styles[i],gram_targets[i])/(n_c**2)\n",
        "\n",
        "        total_loss = c_loss+s_loss\n",
        "\n",
        "        l_c.append(c_loss)\n",
        "        l_s.append(s_loss)\n",
        "        \n",
        "        total_loss.backward()\n",
        "        return total_loss\n",
        "\n",
        "    optimizer.step(closure)\n",
        "    \n",
        "    print('Step {}: S_loss: {:.8f} C_loss: {:.8f}'.format(itr, l_s[-1], l_c[-1]))\n",
        "    \n",
        "\n",
        "    if itr%1 == 0:\n",
        "        temp = unload(image[0].cpu().detach())\n",
        "        temp = to_image(temp)\n",
        "        temp = np.array(temp)\n",
        "        images.append(temp)\n",
        "        imageio.mimsave('progress.gif', images)\n",
        "        \n",
        "    \n",
        "    plt.clf()\n",
        "    plt.plot(l_c, label='Content Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss1.png')\n",
        "    \n",
        "    plt.clf()\n",
        "    plt.plot(l_s, label='Style Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDMMXhL7iTh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imsave('last.jpg',images[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNmnh2JwxpLl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}